{"cells":[{"attachments":{},"cell_type":"markdown","id":"df86bbdf-1c15-4a6b-b7be-0dbe3d36185b","metadata":{},"source":["# Machine Learning Foundation\n","\n","## Section 2, Part d:  Regularization and Gradient Descent\n"]},{"attachments":{},"cell_type":"markdown","id":"1ce18cd8-d1e3-4bb6-bff3-776aa0e3b843","metadata":{},"source":["## Introduction\n","\n","We will begin with a short tutorial on regression, polynomial features, and regularization based on a very simple, sparse data set that contains a column of `x` data and associated `y` noisy data. The data file is called `X_Y_Sinusoid_Data.csv`.\n"]},{"attachments":{},"cell_type":"markdown","id":"011ec1aa-0974-49cf-a983-c809bbed5e58","metadata":{},"source":["## Question 1\n","\n","*   Import the data.\n","\n","*   Also generate approximately 100 equally spaced x data points over the range of 0 to 1. Using these points, calculate the y-data which represents the \"ground truth\" (the real function) from the equation: $y = sin(2\\pi x)$\n","\n","*   Plot the sparse data (`x` vs `y`) and the calculated (\"real\") data.\n"]},{"cell_type":"code","execution_count":1,"id":"6375d59d-4bad-4f76-b135-8f003c143143","metadata":{},"outputs":[],"source":["# Surpress warnings from using older version of sklearn:\n","def warn(*args, **kwargs):\n","    pass\n","import warnings\n","warnings.warn = warn"]},{"cell_type":"code","execution_count":2,"id":"ba8c111d-f299-4aed-8173-86bd89d99738","metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","\n","data = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML240EN-SkillsNetwork/labs/data/X_Y_Sinusoid_Data.csv\")\n","data.head()\n","\n","X_real = np.linspace(0, 1.0, 100)\n","Y_real = np.sin(2 * np.pi * X_real)"]},{"cell_type":"code","execution_count":3,"id":"d10b6015-e383-47b6-84df-0ab4066794c2","metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"id":"06e1b9e4-8b8e-4210-98d8-ec22681b94ff","metadata":{},"outputs":[],"source":["sns.set_style('white')\n","sns.set_context('talk')\n","sns.set_palette('dark')\n","\n","# Plot of the noisy (sparse)\n","ax = data.set_index('x')['y'].plot(ls='', marker='o', label='data')\n","ax.plot(X_real, Y_real, ls='--', marker='', label='real function')\n","\n","ax.legend()\n","ax.set(xlabel='x data', ylabel='y data');\n"]},{"attachments":{},"cell_type":"markdown","id":"3048e0af-dff9-485f-8968-ba26256c9bfd","metadata":{},"source":["## Question 2\n","\n","*   Using the `PolynomialFeatures` class from Scikit-learn's preprocessing library, create 20th order polynomial features.\n","*   Fit this data using linear regression.\n","*   Plot the resulting predicted value compared to the calculated data.\n","\n","Note that `PolynomialFeatures` requires either a dataframe (with one column, not a Series) or a 2D array of dimension (`X`, 1), where `X` is the length.\n"]},{"cell_type":"code","execution_count":null,"id":"1fe39f48-df52-409e-9ffb-86841cd907d1","metadata":{},"outputs":[],"source":["from sklearn.preprocessing import PolynomialFeatures\n","from sklearn.linear_model import LinearRegression\n","\n","# Setup the polynomial features\n","degree = 20\n","pf = PolynomialFeatures(degree)\n","lr = LinearRegression()\n","\n","# Extract the X- and Y- data from the dataframe \n","X_data = data[['x']]\n","Y_data = data['y']\n","\n","# Create the features and fit the model\n","X_poly = pf.fit_transform(X_data)\n","lr = lr.fit(X_poly, Y_data)\n","Y_pred = lr.predict(X_poly)\n","\n","# Plot the result\n","plt.plot(X_data, Y_data, marker='o', ls='', label='data', alpha=1)\n","plt.plot(X_real, Y_real, ls='--', label='real function')\n","plt.plot(X_data, Y_pred, marker='^', alpha=.5, label='predictions w/ polynomial features')\n","plt.legend()\n","ax = plt.gca()\n","ax.set(xlabel='x data', ylabel='y data');\n"]},{"attachments":{},"cell_type":"markdown","id":"e8c1b691-01ae-4206-894b-5139429425de","metadata":{},"source":["## Question 3\n","\n","*   Perform the regression on using the data with polynomial features using ridge regression ($\\alpha$=0.001) and lasso regression ($\\alpha$=0.0001).\n","*   Plot the results, as was done in Question 1.\n","*   Also plot the magnitude of the coefficients obtained from these regressions, and compare them to those obtained from linear regression in the previous question. The linear regression coefficients will likely need a separate plot (or their own y-axis) due to their large magnitude.\n","\n","What does the comparatively large magnitude of the data tell you about the role of regularization?\n"]},{"cell_type":"code","execution_count":null,"id":"27939362-030b-4fde-aecc-7cd8c4b33d20","metadata":{},"outputs":[],"source":["# Mute the sklearn warning about regularization\n","import warnings\n","warnings.filterwarnings('ignore', module='sklearn')\n","\n","from sklearn.linear_model import Ridge, Lasso\n","\n","# The ridge regression model\n","rr = Ridge(alpha=0.001)\n","rr = rr.fit(X_poly, Y_data)\n","Y_pred_rr = rr.predict(X_poly)\n","\n","# The lasso regression model\n","lassor = Lasso(alpha=0.0001)\n","lassor = lassor.fit(X_poly, Y_data)\n","Y_pred_lr = lassor.predict(X_poly)\n","\n","# The plot of the predicted values\n","plt.plot(X_data, Y_data, marker='o', ls='', label='data')\n","plt.plot(X_real, Y_real, ls='--', label='real function')\n","plt.plot(X_data, Y_pred, label='linear regression', marker='^', alpha=.5)\n","plt.plot(X_data, Y_pred_rr, label='ridge regression', marker='^', alpha=.5)\n","plt.plot(X_data, Y_pred_lr, label='lasso regression', marker='^', alpha=.5)\n","\n","plt.legend()\n","\n","ax = plt.gca()\n","ax.set(xlabel='x data', ylabel='y data');"]},{"cell_type":"code","execution_count":null,"id":"b3b2190a-a769-4590-acdd-ed2807a3106c","metadata":{},"outputs":[],"source":["# let's look at the absolute value of coefficients for each model\n","\n","coefficients = pd.DataFrame()\n","coefficients['linear regression'] = lr.coef_.ravel()\n","coefficients['ridge regression'] = rr.coef_.ravel()\n","coefficients['lasso regression'] = lassor.coef_.ravel()\n","coefficients = coefficients.applymap(abs)\n","\n","coefficients.describe()  # Huge difference in scale between non-regularized vs regularized regression"]},{"cell_type":"code","execution_count":null,"id":"1bf8d2b2-1113-4863-8a3a-47a30b34756c","metadata":{},"outputs":[],"source":["colors = sns.color_palette()\n","\n","# Setup the dual y-axes\n","ax1 = plt.axes()\n","ax2 = ax1.twinx()\n","\n","# Plot the linear regression data\n","ax1.plot(lr.coef_.ravel(), \n","         color=colors[0], marker='o', label='linear regression')\n","\n","# Plot the regularization data sets\n","ax2.plot(rr.coef_.ravel(), \n","         color=colors[1], marker='o', label='ridge regression')\n","\n","ax2.plot(lassor.coef_.ravel(), \n","         color=colors[2], marker='o', label='lasso regression')\n","\n","# Customize axes scales\n","ax1.set_ylim(-2e14, 2e14)\n","ax2.set_ylim(-25, 25)\n","\n","# Combine the legends\n","h1, l1 = ax1.get_legend_handles_labels()\n","h2, l2 = ax2.get_legend_handles_labels()\n","ax1.legend(h1+h2, l1+l2)\n","\n","ax1.set(xlabel='coefficients',ylabel='linear regression')\n","ax2.set(ylabel='ridge and lasso regression')\n","\n","ax1.set_xticks(range(len(lr.coef_)));"]},{"attachments":{},"cell_type":"markdown","id":"c0e4a5b6-29f7-418c-86a0-908a07c834ad","metadata":{},"source":["## Question 4\n","\n","For the remaining questions, we will be working with the [data set](https://www.kaggle.com/c/house-prices-advanced-regression-techniques?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML240ENSkillsNetwork34171862-2022-01-01) from last lesson, which is based on housing prices in Ames, Iowa. There are an extensive number of features--see the exercises from week three for a discussion of these features.\n","\n","To begin:\n","\n","*   Import the data with Pandas, remove any null values, and one hot encode categoricals. Either Scikit-learn's feature encoders or Pandas `get_dummies` method can be used.\n","*   Split the data into train and test sets.\n","*   Log transform skewed features.\n","*   Scaling can be attempted, although it can be interesting to see how well regularization works without scaling features.\n"]},{"cell_type":"code","execution_count":4,"id":"002d3aa5-628e-4547-8ed6-f13e3e6da36c","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>1stFlrSF</th>\n","      <th>2ndFlrSF</th>\n","      <th>3SsnPorch</th>\n","      <th>Alley</th>\n","      <th>BedroomAbvGr</th>\n","      <th>BldgType</th>\n","      <th>BsmtCond</th>\n","      <th>BsmtExposure</th>\n","      <th>BsmtFinSF1</th>\n","      <th>BsmtFinSF2</th>\n","      <th>...</th>\n","      <th>ScreenPorch</th>\n","      <th>Street</th>\n","      <th>TotRmsAbvGrd</th>\n","      <th>TotalBsmtSF</th>\n","      <th>Utilities</th>\n","      <th>WoodDeckSF</th>\n","      <th>YearBuilt</th>\n","      <th>YearRemodAdd</th>\n","      <th>YrSold</th>\n","      <th>SalePrice</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>856.0</td>\n","      <td>854.0</td>\n","      <td>0.0</td>\n","      <td>None</td>\n","      <td>3</td>\n","      <td>1Fam</td>\n","      <td>TA</td>\n","      <td>No</td>\n","      <td>706.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>Pave</td>\n","      <td>8</td>\n","      <td>856.0</td>\n","      <td>AllPub</td>\n","      <td>0.0</td>\n","      <td>2003</td>\n","      <td>2003</td>\n","      <td>2008</td>\n","      <td>208500.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1262.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>None</td>\n","      <td>3</td>\n","      <td>1Fam</td>\n","      <td>TA</td>\n","      <td>Gd</td>\n","      <td>978.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>Pave</td>\n","      <td>6</td>\n","      <td>1262.0</td>\n","      <td>AllPub</td>\n","      <td>298.0</td>\n","      <td>1976</td>\n","      <td>1976</td>\n","      <td>2007</td>\n","      <td>181500.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>920.0</td>\n","      <td>866.0</td>\n","      <td>0.0</td>\n","      <td>None</td>\n","      <td>3</td>\n","      <td>1Fam</td>\n","      <td>TA</td>\n","      <td>Mn</td>\n","      <td>486.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>Pave</td>\n","      <td>6</td>\n","      <td>920.0</td>\n","      <td>AllPub</td>\n","      <td>0.0</td>\n","      <td>2001</td>\n","      <td>2002</td>\n","      <td>2008</td>\n","      <td>223500.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>961.0</td>\n","      <td>756.0</td>\n","      <td>0.0</td>\n","      <td>None</td>\n","      <td>3</td>\n","      <td>1Fam</td>\n","      <td>Gd</td>\n","      <td>No</td>\n","      <td>216.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>Pave</td>\n","      <td>7</td>\n","      <td>756.0</td>\n","      <td>AllPub</td>\n","      <td>0.0</td>\n","      <td>1915</td>\n","      <td>1970</td>\n","      <td>2006</td>\n","      <td>140000.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1145.0</td>\n","      <td>1053.0</td>\n","      <td>0.0</td>\n","      <td>None</td>\n","      <td>4</td>\n","      <td>1Fam</td>\n","      <td>TA</td>\n","      <td>Av</td>\n","      <td>655.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>Pave</td>\n","      <td>9</td>\n","      <td>1145.0</td>\n","      <td>AllPub</td>\n","      <td>192.0</td>\n","      <td>2000</td>\n","      <td>2000</td>\n","      <td>2008</td>\n","      <td>250000.0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>796.0</td>\n","      <td>566.0</td>\n","      <td>320.0</td>\n","      <td>None</td>\n","      <td>1</td>\n","      <td>1Fam</td>\n","      <td>TA</td>\n","      <td>No</td>\n","      <td>732.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>Pave</td>\n","      <td>5</td>\n","      <td>796.0</td>\n","      <td>AllPub</td>\n","      <td>40.0</td>\n","      <td>1993</td>\n","      <td>1995</td>\n","      <td>2009</td>\n","      <td>143000.0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>1694.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>None</td>\n","      <td>3</td>\n","      <td>1Fam</td>\n","      <td>TA</td>\n","      <td>Av</td>\n","      <td>1369.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>Pave</td>\n","      <td>7</td>\n","      <td>1686.0</td>\n","      <td>AllPub</td>\n","      <td>255.0</td>\n","      <td>2004</td>\n","      <td>2005</td>\n","      <td>2007</td>\n","      <td>307000.0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1107.0</td>\n","      <td>983.0</td>\n","      <td>0.0</td>\n","      <td>None</td>\n","      <td>3</td>\n","      <td>1Fam</td>\n","      <td>TA</td>\n","      <td>Mn</td>\n","      <td>859.0</td>\n","      <td>32.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>Pave</td>\n","      <td>7</td>\n","      <td>1107.0</td>\n","      <td>AllPub</td>\n","      <td>235.0</td>\n","      <td>1973</td>\n","      <td>1973</td>\n","      <td>2009</td>\n","      <td>200000.0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1022.0</td>\n","      <td>752.0</td>\n","      <td>0.0</td>\n","      <td>None</td>\n","      <td>2</td>\n","      <td>1Fam</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>Pave</td>\n","      <td>8</td>\n","      <td>952.0</td>\n","      <td>AllPub</td>\n","      <td>90.0</td>\n","      <td>1931</td>\n","      <td>1950</td>\n","      <td>2008</td>\n","      <td>129900.0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>1077.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>None</td>\n","      <td>2</td>\n","      <td>2fmCon</td>\n","      <td>TA</td>\n","      <td>No</td>\n","      <td>851.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>Pave</td>\n","      <td>5</td>\n","      <td>991.0</td>\n","      <td>AllPub</td>\n","      <td>0.0</td>\n","      <td>1939</td>\n","      <td>1950</td>\n","      <td>2008</td>\n","      <td>118000.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10 rows × 80 columns</p>\n","</div>"],"text/plain":["   1stFlrSF  2ndFlrSF  3SsnPorch Alley  BedroomAbvGr BldgType BsmtCond  \\\n","0     856.0     854.0        0.0  None             3     1Fam       TA   \n","1    1262.0       0.0        0.0  None             3     1Fam       TA   \n","2     920.0     866.0        0.0  None             3     1Fam       TA   \n","3     961.0     756.0        0.0  None             3     1Fam       Gd   \n","4    1145.0    1053.0        0.0  None             4     1Fam       TA   \n","5     796.0     566.0      320.0  None             1     1Fam       TA   \n","6    1694.0       0.0        0.0  None             3     1Fam       TA   \n","7    1107.0     983.0        0.0  None             3     1Fam       TA   \n","8    1022.0     752.0        0.0  None             2     1Fam     None   \n","9    1077.0       0.0        0.0  None             2   2fmCon       TA   \n","\n","  BsmtExposure  BsmtFinSF1  BsmtFinSF2  ... ScreenPorch Street  TotRmsAbvGrd  \\\n","0           No       706.0         0.0  ...         0.0   Pave             8   \n","1           Gd       978.0         0.0  ...         0.0   Pave             6   \n","2           Mn       486.0         0.0  ...         0.0   Pave             6   \n","3           No       216.0         0.0  ...         0.0   Pave             7   \n","4           Av       655.0         0.0  ...         0.0   Pave             9   \n","5           No       732.0         0.0  ...         0.0   Pave             5   \n","6           Av      1369.0         0.0  ...         0.0   Pave             7   \n","7           Mn       859.0        32.0  ...         0.0   Pave             7   \n","8         None         0.0         0.0  ...         0.0   Pave             8   \n","9           No       851.0         0.0  ...         0.0   Pave             5   \n","\n","   TotalBsmtSF Utilities  WoodDeckSF YearBuilt YearRemodAdd YrSold SalePrice  \n","0        856.0    AllPub         0.0      2003         2003   2008  208500.0  \n","1       1262.0    AllPub       298.0      1976         1976   2007  181500.0  \n","2        920.0    AllPub         0.0      2001         2002   2008  223500.0  \n","3        756.0    AllPub         0.0      1915         1970   2006  140000.0  \n","4       1145.0    AllPub       192.0      2000         2000   2008  250000.0  \n","5        796.0    AllPub        40.0      1993         1995   2009  143000.0  \n","6       1686.0    AllPub       255.0      2004         2005   2007  307000.0  \n","7       1107.0    AllPub       235.0      1973         1973   2009  200000.0  \n","8        952.0    AllPub        90.0      1931         1950   2008  129900.0  \n","9        991.0    AllPub         0.0      1939         1950   2008  118000.0  \n","\n","[10 rows x 80 columns]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["data = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML240EN-SkillsNetwork/labs/data/Ames_Housing_Sales.csv\")\n","data.head(10)"]},{"attachments":{},"cell_type":"markdown","id":"ff6559b1-c4ab-47b6-b38d-c343deb5faaa","metadata":{},"source":["Create a list of categorial data and one-hot encode. Pandas one-hot encoder (`get_dummies`) works well with data that is defined as a categorical.\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["(1379, 80)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["data.shape"]},{"cell_type":"code","execution_count":null,"id":"b343c833-78c5-4c9d-bd85-921eb5c7b81b","metadata":{},"outputs":[],"source":["data =pd.get_dummies(data, drop_first=True)\n","data.columns"]},{"attachments":{},"cell_type":"markdown","id":"25ba60a4-8c68-40c2-ad40-553fdd56def8","metadata":{},"source":["Next, split the data in train and test data sets.\n"]},{"cell_type":"code","execution_count":null,"id":"c7c516b0-1814-4f38-b656-d25c6fe4d46e","metadata":{},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","train, test = train_test_split(data, test_size=0.3, random_state=42)"]},{"attachments":{},"cell_type":"markdown","id":"60289104-ab24-407d-ba03-9e56d2803fcf","metadata":{},"source":["There are a number of columns that have skewed features--a log transformation can be applied to them. Note that this includes the `SalePrice`, our predictor. However, let's keep that one as is.\n"]},{"cell_type":"code","execution_count":null,"id":"e932a6d1-b06f-4696-8ac1-09eca91480da","metadata":{},"outputs":[],"source":["# Create a list of float colums to check for skewing\n","mask = data.dtypes == np.float\n","float_cols = data.columns[mask]"]},{"cell_type":"code","execution_count":null,"id":"ed345c64-9f2b-4f53-bec5-3fd65d87fc58","metadata":{},"outputs":[],"source":["skew_limit = 0.75\n","skew_vals = train[float_cols].skew()\n","\n","skew_cols = (skew_vals\n","             .sort_values(ascending=False)\n","             .to_frame()\n","             .rename(columns={0:'Skew'})\n","             .query('abs(Skew) > {0}'.format(skew_limit)))\n","\n","skew_cols"]},{"attachments":{},"cell_type":"markdown","id":"e2befca7-7e20-4b0f-99d6-137c17f52b69","metadata":{},"source":["Transform all the columns where the skew is greater than 0.75, excluding \"SalePrice\".\n"]},{"cell_type":"code","execution_count":null,"id":"53084aad-1611-4ea2-a58e-ecf295204ab3","metadata":{},"outputs":[],"source":["# OPTIONAL: Let's look at what happens to one of these features, when we apply np.log1p visually.\n","\n","field = \"BsmtFinSF1\"\n","fig, (ax_before, ax_after) = plt.subplots(1, 2, figsize=(10, 5))\n","train[field].hist(ax=ax_before)\n","train[field].apply(np.log1p).hist(ax=ax_after)\n","ax_before.set(title='before np.log1p', ylabel='frequency', xlabel='value')\n","ax_after.set(title='after np.log1p', ylabel='frequency', xlabel='value')\n","fig.suptitle('Field \"{}\"'.format(field));\n","# a little bit better"]},{"cell_type":"code","execution_count":null,"id":"23d7680a-b9a2-4a6b-a024-1fcf57b83199","metadata":{},"outputs":[],"source":["# Mute the setting wtih a copy warnings\n","pd.options.mode.chained_assignment = None\n","\n","for col in skew_cols.index.tolist():\n","    if col == \"SalePrice\":\n","        continue\n","    train[col] = np.log1p(train[col])\n","    test[col]  = test[col].apply(np.log1p)  # same thing"]},{"attachments":{},"cell_type":"markdown","id":"c542ad19-a02c-4266-8b80-1d3874293ec2","metadata":{},"source":["Separate features from predictor.\n"]},{"cell_type":"code","execution_count":null,"id":"fcb2311e-9e5f-4e73-b712-f7c5c4aac1d6","metadata":{},"outputs":[],"source":["feature_cols = [x for x in train.columns if x != 'SalePrice']\n","X_train = train[feature_cols]\n","y_train = train['SalePrice']\n","\n","X_test  = test[feature_cols]\n","y_test  = test['SalePrice']"]},{"attachments":{},"cell_type":"markdown","id":"a99beb1e-8a7f-4908-afee-02ccb61f8588","metadata":{},"source":["## Question 5\n","\n","*   Write a function **`rmse`** that takes in truth and prediction values and returns the root-mean-squared error. Use sklearn's `mean_squared_error`.\n"]},{"cell_type":"code","execution_count":null,"id":"e7a99196-449f-42cd-9067-d78822b37dc5","metadata":{},"outputs":[],"source":["from sklearn.metrics import mean_squared_error\n","\n","\n","def rmse(ytrue, ypredicted):\n","    return np.sqrt(mean_squared_error(ytrue, ypredicted))"]},{"attachments":{},"cell_type":"markdown","id":"1edc4c1a-c2aa-471f-b51c-b79be10f2b1c","metadata":{},"source":["*   Fit a basic linear regression model\n","*   print the root-mean-squared error for this model\n","*   plot the predicted vs actual sale price based on the model.\n"]},{"cell_type":"code","execution_count":null,"id":"8a7943d0-4001-47d1-b864-c29a3dbf2846","metadata":{},"outputs":[],"source":["from sklearn.linear_model import LinearRegression\n","\n","linearRegression = LinearRegression().fit(X_train, y_train)\n","\n","linearRegression_rmse = rmse(y_test, linearRegression.predict(X_test))\n","\n","print(linearRegression_rmse)"]},{"cell_type":"code","execution_count":null,"id":"7a5d5c61-e312-4a5c-8ac9-e299e2c8c3d9","metadata":{},"outputs":[],"source":["f = plt.figure(figsize=(6,6))\n","ax = plt.axes()\n","\n","ax.plot(y_test, linearRegression.predict(X_test), \n","         marker='o', ls='', ms=3.0)\n","\n","lim = (0, y_test.max())\n","\n","ax.set(xlabel='Actual Price', \n","       ylabel='Predicted Price', \n","       xlim=lim,\n","       ylim=lim,\n","       title='Linear Regression Results');"]},{"attachments":{},"cell_type":"markdown","id":"ee9b229f-c147-4db0-bb72-2874a15326aa","metadata":{},"source":["## Question 6\n","\n","Ridge regression uses L2 normalization to reduce the magnitude of the coefficients. This can be helpful in situations where there is high variance. The regularization functions in Scikit-learn each contain versions that have cross-validation built in.\n","\n","*   Fit a regular (non-cross validated) Ridge model to a range of $\\alpha$ values and plot the RMSE using the cross validated error function you created above.\n","*   Use $$\\[0.005, 0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 80]$$ as the range of alphas.\n","*   Then repeat the fitting of the Ridge models using the range of $\\alpha$ values from the prior section. Compare the results.\n"]},{"attachments":{},"cell_type":"markdown","id":"576c2413-9358-4e7e-ae2c-8e7082d45674","metadata":{},"source":["Now for the `RidgeCV` method. It's not possible to get the alpha values for the models that weren't selected, unfortunately. The resulting error values and $\\alpha$ values are very similar to those obtained above.\n"]},{"cell_type":"code","execution_count":null,"id":"d59c3a4b-1953-47ae-a61a-84829b2c35be","metadata":{},"outputs":[],"source":["from sklearn.linear_model import RidgeCV\n","\n","alphas = [0.005, 0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 80]\n","\n","ridgeCV = RidgeCV(alphas=alphas, \n","                  cv=4).fit(X_train, y_train)\n","\n","ridgeCV_rmse = rmse(y_test, ridgeCV.predict(X_test))\n","\n","print(ridgeCV.alpha_, ridgeCV_rmse)"]},{"attachments":{},"cell_type":"markdown","id":"a7b0b1ab-381a-4566-ab39-f6e295a61327","metadata":{},"source":["## Question 7\n","\n","Much like the `RidgeCV` function, there is also a `LassoCV` function that uses an L1 regularization function and cross-validation. L1 regularization will selectively shrink some coefficients, effectively performing feature elimination.\n","\n","The `LassoCV` function does not allow the scoring function to be set. However, the custom error function (`rmse`) created above can be used to evaluate the error on the final model.\n","\n","Similarly, there is also an elastic net function with cross validation, `ElasticNetCV`, which is a combination of L2 and L1 regularization.\n","\n","*   Fit a Lasso model using cross validation and determine the optimum value for $\\alpha$ and the RMSE using the function created above. Note that the magnitude of $\\alpha$ may be different from the Ridge model.\n","*   Repeat this with the Elastic net model.\n","*   Compare the results via table and/or plot.\n","\n","Use the following alphas:\\\n","`[1e-5, 5e-5, 0.0001, 0.0005]`\n"]},{"cell_type":"code","execution_count":null,"id":"5df912ba-4e64-4397-8a09-18b88b7bc7ef","metadata":{},"outputs":[],"source":["from sklearn.linear_model import LassoCV\n","\n","alphas2 = np.array([1e-5, 5e-5, 0.0001, 0.0005])\n","\n","lassoCV = LassoCV(alphas=alphas2,\n","                  max_iter=5e4,\n","                  cv=3).fit(X_train, y_train)\n","\n","lassoCV_rmse = rmse(y_test, lassoCV.predict(X_test))\n","\n","print(lassoCV.alpha_, lassoCV_rmse)  # Lasso is slower"]},{"attachments":{},"cell_type":"markdown","id":"3fafd0dd-01fe-4f68-b9b1-ce4160f5779f","metadata":{},"source":["We can determine how many of these features remain non-zero.\n"]},{"cell_type":"code","execution_count":null,"id":"433f76fa-617d-4068-b2eb-21f8d518af41","metadata":{},"outputs":[],"source":["print('Of {} coefficients, {} are non-zero with Lasso.'.format(len(lassoCV.coef_), \n","                                                               len(lassoCV.coef_.nonzero()[0])))"]},{"attachments":{},"cell_type":"markdown","id":"8a418dbe-9d17-49da-8c38-4b90b57cd9b3","metadata":{},"source":["Now try the elastic net, with the same alphas as in Lasso, and l1\\_ratios between 0.1 and 0.9\n"]},{"cell_type":"code","execution_count":null,"id":"92791523-2eee-4931-8f92-399e10346885","metadata":{},"outputs":[],"source":["from sklearn.linear_model import ElasticNetCV\n","\n","l1_ratios = np.linspace(0.1, 0.9, 9)\n","\n","elasticNetCV = ElasticNetCV(alphas=alphas2, \n","                            l1_ratio=l1_ratios,\n","                            max_iter=1e4).fit(X_train, y_train)\n","elasticNetCV_rmse = rmse(y_test, elasticNetCV.predict(X_test))\n","\n","print(elasticNetCV.alpha_, elasticNetCV.l1_ratio_, elasticNetCV_rmse)"]},{"attachments":{},"cell_type":"markdown","id":"3ba6762f-3c39-4ef7-ad91-e46f0b0d8d9c","metadata":{},"source":["Comparing the RMSE calculation from all models is easiest in a table.\n"]},{"cell_type":"code","execution_count":null,"id":"04776496-c0fe-490c-a1b2-c1e59677bda7","metadata":{},"outputs":[],"source":["rmse_vals = [linearRegression_rmse, ridgeCV_rmse, lassoCV_rmse, elasticNetCV_rmse]\n","\n","labels = ['Linear', 'Ridge', 'Lasso', 'ElasticNet']\n","\n","rmse_df = pd.Series(rmse_vals, index=labels).to_frame()\n","rmse_df.rename(columns={0: 'RMSE'}, inplace=1)\n","rmse_df"]},{"attachments":{},"cell_type":"markdown","id":"ca92a547-898c-428b-a35d-6979faf34582","metadata":{},"source":["We can also make a plot of actual vs predicted housing prices as before.\n"]},{"cell_type":"code","execution_count":null,"id":"592839ec-9ac0-4e7b-9e88-bd6e124be5e7","metadata":{},"outputs":[],"source":["f = plt.figure(figsize=(6,6))\n","ax = plt.axes()\n","\n","labels = ['Ridge', 'Lasso', 'ElasticNet']\n","\n","models = [ridgeCV, lassoCV, elasticNetCV]\n","\n","for mod, lab in zip(models, labels):\n","    ax.plot(y_test, mod.predict(X_test), \n","             marker='o', ls='', ms=3.0, label=lab)\n","\n","\n","leg = plt.legend(frameon=True)\n","leg.get_frame().set_edgecolor('black')\n","leg.get_frame().set_linewidth(1.0)\n","\n","ax.set(xlabel='Actual Price', \n","       ylabel='Predicted Price', \n","       title='Linear Regression Results');"]},{"attachments":{},"cell_type":"markdown","id":"f70ba8af-a242-4d1b-a78b-c640233422fc","metadata":{},"source":["## Question 8\n","\n","Let's explore Stochastic gradient descent in this exercise.\\\n","Recall that Linear models in general are sensitive to scaling.\n","However, SGD is *very* sensitive to scaling.\\\n","Moreover, a high value of learning rate can cause the algorithm to diverge, whereas a too low value may take too long to converge.\n","\n","*   Fit a stochastic gradient descent model without a regularization penalty (the relevant parameter is `penalty`).\n","*   Now fit stochastic gradient descent models with each of the three penalties (L2, L1, Elastic Net) using the parameter values determined by cross validation above.\n","*   Do not scale the data before fitting the model.\n","*   Compare the results to those obtained without using stochastic gradient descent.\n"]},{"cell_type":"code","execution_count":null,"id":"362a4f44-30fb-4e35-8a8e-48e00fa3c28e","metadata":{},"outputs":[],"source":["# Import SGDRegressor and prepare the parameters\n","\n","from sklearn.linear_model import SGDRegressor\n","\n","model_parameters_dict = {\n","    'Linear': {'penalty': 'none'},\n","    'Lasso': {'penalty': 'l2',\n","           'alpha': lassoCV.alpha_},\n","    'Ridge': {'penalty': 'l1',\n","           'alpha': ridgeCV_rmse},\n","    'ElasticNet': {'penalty': 'elasticnet', \n","                   'alpha': elasticNetCV.alpha_,\n","                   'l1_ratio': elasticNetCV.l1_ratio_}\n","}\n","\n","new_rmses = {}\n","for modellabel, parameters in model_parameters_dict.items():\n","    # following notation passes the dict items as arguments\n","    SGD = SGDRegressor(**parameters)\n","    SGD.fit(X_train, y_train)\n","    new_rmses[modellabel] = rmse(y_test, SGD.predict(X_test))\n","\n","rmse_df['RMSE-SGD'] = pd.Series(new_rmses)\n","rmse_df"]},{"attachments":{},"cell_type":"markdown","id":"eda26473-0306-46f1-a3b0-8e371872354c","metadata":{},"source":["Notice how high the error values are! The algorithm is diverging. This can be due to scaling and/or learning rate being too high. Let's adjust the learning rate and see what happens.\n","\n","*   Pass in `eta0=1e-7` when creating the instance of `SGDClassifier`.\n","*   Re-compute the errors for all the penalties and compare.\n"]},{"cell_type":"code","execution_count":null,"id":"0b678756-ee19-4d6d-beb5-b29481e5a69b","metadata":{},"outputs":[],"source":["# Import SGDRegressor and prepare the parameters\n","\n","from sklearn.linear_model import SGDRegressor\n","\n","model_parameters_dict = {\n","    'Linear': {'penalty': 'none'},\n","    'Lasso': {'penalty': 'l2',\n","           'alpha': lassoCV.alpha_},\n","    'Ridge': {'penalty': 'l1',\n","           'alpha': ridgeCV_rmse},\n","    'ElasticNet': {'penalty': 'elasticnet', \n","                   'alpha': elasticNetCV.alpha_,\n","                   'l1_ratio': elasticNetCV.l1_ratio_}\n","}\n","\n","new_rmses = {}\n","for modellabel, parameters in model_parameters_dict.items():\n","    # following notation passes the dict items as arguments\n","    SGD = SGDRegressor(eta0=1e-7, **parameters)\n","    SGD.fit(X_train, y_train)\n","    new_rmses[modellabel] = rmse(y_test, SGD.predict(X_test))\n","\n","rmse_df['RMSE-SGD-learningrate'] = pd.Series(new_rmses)\n","rmse_df"]},{"attachments":{},"cell_type":"markdown","id":"4dfd522d-e595-443a-8e2e-1e52792a30b4","metadata":{},"source":["Now let's scale our training data and try again.\n","\n","*   Fit a `MinMaxScaler` to `X_train` create a variable `X_train_scaled`.\n","*   Using the scaler, transform `X_test` and create a variable `X_test_scaled`.\n","*   Apply the same versions of SGD to them and compare the results. Don't pass in a eta0 this time.\n"]},{"cell_type":"code","execution_count":null,"id":"3557d54e-3c44-48d9-825d-d3923f54feae","metadata":{},"outputs":[],"source":["from sklearn.preprocessing import MinMaxScaler\n","\n","scaler = MinMaxScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","new_rmses = {}\n","for modellabel, parameters in model_parameters_dict.items():\n","    # following notation passes the dict items as arguments\n","    SGD = SGDRegressor(**parameters)\n","    SGD.fit(X_train_scaled, y_train)\n","    new_rmses[modellabel] = rmse(y_test, SGD.predict(X_test_scaled))\n","\n","rmse_df['RMSE-SGD-scaled'] = pd.Series(new_rmses)\n","rmse_df"]},{"cell_type":"code","execution_count":null,"id":"3835f979-82b4-40ec-9788-6bcd7e5dee9f","metadata":{},"outputs":[],"source":["from sklearn.preprocessing import MinMaxScaler\n","\n","scaler = MinMaxScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","new_rmses = {}\n","for modellabel, parameters in model_parameters_dict.items():\n","    # following notation passes the dict items as arguments\n","    SGD = SGDRegressor(**parameters)\n","    SGD.fit(X_train_scaled, y_train)\n","    new_rmses[modellabel] = rmse(y_test, SGD.predict(X_test_scaled))\n","\n","rmse_df['RMSE-SGD-scaled'] = pd.Series(new_rmses)\n","rmse_df"]},{"attachments":{},"cell_type":"markdown","id":"8fc47cd7-426a-4fae-b967-9c7e3a26186f","metadata":{},"source":["***\n","\n","### Machine Learning Foundation (C) 2020 IBM Corporation\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd \n","import seaborn as sns \n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["<seaborn.axisgrid.FacetGrid at 0x28293f1c340>"]},"execution_count":10,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAWAAAAFgCAYAAACFYaNMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAq6ElEQVR4nO3deXiU5bnH8e+djRD2JewgoCAKyhYg1RapS4vVonUHVBQEulir7emp3bT1dLFqW9vaWkAQF8Bal6rHuldET2WXVaJoRHbCGsg+y33+mClFCoqQmXcy8/tcF1eSN2He21zjlydPZt4xd0dERJIvK+gBREQylQIsIhIQBVhEJCAKsIhIQBRgEZGA5AQ9wJEYOXKkP//880GPISJytOxQBxvECnjHjh1BjyAiUu8aRIBFRNKRAiwiEhAFWEQkIAqwiEhAFGARkYAowCIiAVGARUQCogCLiAREARYRCUiDeCqyiEiQ5paUMWVeKRt2V9G1VQGTh/dkRJ92x3y7WgGLiHyMuSVl3PL0araWV9OycS5l+2q45enVzC0pO+bbVoBFRD7GlHmlGM6mPTVsr6ilIC+H3GxjyrzSY75tBVhE5GOs21nJlvIa6iJRyvbVUheO0jg3m427q475thVgEZHD2La3ht1VddRFHAO6t2lCXk4W1aEIXVoVHPPtK8AiIodQtreG0VPnUxOKYkCHFvk0ycumqi5MKOJMHt7zmM+hAIuIHKRsXw1XTJtP6Y5K8nKy+M45venepgnl1SHaNcvntlF96+VREHoYmojIAbbvq2XMtAWUbo/Fd+pVgxlxYjuuP6tXvZ9LK2ARkbgdFbWMmTaf98oqyMvOYko8vomiAIuIADvj8V1bVkFutvHnqwbx+QTGFxRgERF2VdYx9r4FvLstFt97xw7mzD7tE35eBVhEMtrueHxLtu4jN9v409jBnH1y4uMLCrCIZLB/xXfNlr3kZBn3jBnEOUmKLyjAIpKh9lTVceX0Bby9P74D+WLfDkmdQQEWkYxTXhXiyukLWL15L9lZxh9GD2Rkv45Jn0MBFpGMUl4di++qTbH4/v6KgZx7SvLjCwqwiGSQvTUhrp6+gJWbyskyuPvyAZx3ajDxBQVYRDLEvpoQV09fyPKNsfj+9vIBfLl/p0BnSliAzayrmb1qZmvMbLWZfSt+/E4zKzGzFWb2pJm1TNQMIiIQi++4GQtZtmHP/vheMKBz0GMldAUcBr7j7icBxcA3zOxk4CWgn7ufCrwLfD+BM4hIhquoDXPN/YtYun4PZvDry/qnRHwhgQF29y3uvjT+/j5gDdDZ3V9093D8y+YDXRI1g4hktoraMNfMWMiSD3djBnde0p+vDEyd5CRlD9jMugMDgQUHfWo88Nxh/s4kM1tsZou3b9+e4AlFJN1U1oYZf/8iFsfj+6uLT+WSwakTX0hCgM2sKfA4cKO77z3g+A+JbVPMOtTfc/ep7l7k7kWFhYWJHlNE0khVXZjxMxexcN0uAG6/6BQuK+oa8FT/KaHXAzazXGLxneXuTxxwfBxwPnCWu3siZxCRzFJdF2H8zEUs+CAW319edAqXD+kW8FSHlrAAm5kB04E17v6bA46PBL4HnOHux/6qdiIicdV1ESY8sIj5pbH4/vwr/Rg9NDXjC4ldAZ8OXAWsNLNl8WM/AH4PNAJeijWa+e7+1QTOISIZoCYUYeKDi/nn+zsB+J8L+zF22HEBT/XxEhZgd38DsEN86u+JOqeIZKZ/xfeN93YAcNsFfbmqOLXjC3omnIg0cDWhCJMeWsLra2PxvfXLJ3P1Z7oHO9QRUoBFpMGqCUWY/NAS5r0be6jqj88/mWtP7xHwVEdOARaRBqk2HOFrDy/htXh8f3TeSUz4bMOJLyjAItIA1YYjfP3hpbz6Tiy+P/hSH677XM+Ap/r0FGARaVDqwlG+MestXikpA+Dmc/swafjxAU91dBRgEWkwQpEo189eystrtgHw3yNP5KtnNMz4ggIsIg1EKBLlm7Pf4sW3Y/H9ry/05usjTgh4qmOjAItIygtFonzrkbd4fvVWAL59Tm+uP7NXwFMdu4ReC0JE5GjNLSljyrxS1u+qpCYUZWdlHQA3nt2LG85q+PEFBVhEUtDckjJueXo1OVmxa/qWV8cuIX5B/07ceHbvgKerP9qCEJGUM2VeKTlZsLMytD++rQpy2ba3JuDJ6pdWwCKSctbvqqSiNkJ5dQiAwqaNaNcsj017qgOerH5pBSwiKSUSderC/pH4tm/eiJpwlC6tCgKern4pwCKSMqJR53uPr2B7RS0ALRvn0q5ZHtWhCKGIM3l4w3u228fRFoSIpIRo1Ln5iRU8tmQjACP7tmdPVYhNe6rp0qqAycN7MqJPu4CnrF8KsIgELhp1fvDkSh5dHIvv+NN78OPzTyL+og1pS1sQIhKoaNT54d9W8siiDQBcc1r3jIgvKMAiEiB358dPrWLOwlh8x33mOG798skZEV9QgEUkIO7OLU+tZtaC9QBcVXwcPxnVN2PiCwqwiATA3fnJ06t5aP6HAIwd1o2fZlh8QQEWkSRzd376zNs88GYsvqOHduV/LuhHVlZmxRcUYBFJInfnZ8+uYeY/1wFweVFXfn7hKRkZX1CARSRJ3J2fP7uG6W98AMClg7vwy4syN76gAItIErg7v3yuhPvi8b1kcBd+dfGpGR1fUIBFJMHcndufL2HqvFIALhrUWfGNU4BFJGHcnTteeIcpr8Xi+5WBnbnzkv5kK75AAgNsZl3N7FUzW2Nmq83sW/Hjrc3sJTNbG3/bKlEziEhw3J1fv/gu9859H4ALBnTirksV3wMlcgUcBr7j7icBxcA3zOxk4GbgFXfvBbwS/1hE0sxvX17LPa++B8CX+3fi14rvf0hYgN19i7svjb+/D1gDdAYuAB6If9kDwIWJmkFEgnH3y+/y+1fWAnDeqR357WX9ycnWjufBkvIdMbPuwEBgAdDe3bdALNLAIa8vZ2aTzGyxmS3evn17MsYUkXrwh1fWcvfLsfh+6ZQO/O7yAYrvYST8u2JmTYHHgRvdfe+R/j13n+ruRe5eVFhYmLgBRaTe3POPtfz6pXcBGNm3A7+7YqDi+zES+p0xs1xi8Z3l7k/ED28zs47xz3cEyhI5g4gkx5/mvsddL8bi+4WT2/OHMQPJVXw/ViIfBWHAdGCNu//mgE89DYyLvz8OeCpRM4hIcvz5tfe54/l3ADj7pPbcM2aQ4nsEEvmKGKcDVwErzWxZ/NgPgNuBR81sArAeuDSBM4hIgk2d9z63P1cCwNknteNPYweRl6P4HomEBdjd3wAO95iTsxJ1XhFJnvteL+UXf4/F98w+7fij4vup6DslIkdlxhsf8LNn1wAw4sRC7r1yEI1ysgOeqmFRgEXkU5v5fx9w2/++DcDw3oX8+crBiu9RUIBF5FN58M11/OSZWHw/16stU68aTH6u4ns0FGAROWIPzf+QW55aDcBnT2jLtKuLFN9joACLyBGZteBDfvy3VQCcfkIbxbceKMAi8onmLFzPD5+MxfczPdtw39VDaJyn+B4rBVhEPtZfFq3n+0+sBGBYj9ZMv6ZI8a0nCrCIHNajizdwczy+Q3u05v5rh1CQl8jnb2UWfSdF5CPmlpQxZV4pJVv3srsqBMCQ7q24/xrFt77puyki+80tKeOWp1dTEwrvj29eThbjT+9Bk0bKRX3TFoSI7DdlXik1oQhl++oAKMjLpnOLfB5888OAJ0tP+idNRPZ7Z9tedlXGVr6Nc7Pp3qYJWQYbd1cFPFl60gpYRAB4Zvnmj8S3R9smZGcZ1aEIXVoVBDxdelKARYRnV2zhxr8sAyAvO4v2zRuRZVBVFyYUcSYP7xnsgGlKARbJcM+t3MINj7xFJOr069yc317Wn44tGlNeHaJds3xuG9WXEX0O+dKNcoy0ByySwZ5ftYVvzonFt2+n5jw8YRgtC/I4r3+noEfLCFoBi2SoF1dv5frZbxGOOid3bM6s62LxleRRgEUy0Etvb+Mbs5cSjjp9OjRTfAOiAItkmJff3sbXZy0hFPl3fFs1UXyDoACLZJB/lGzja/H4ntg+Ft82TRsFPVbGUoBFMsSrJWV89aGlhCJOr3ZNmTVR8Q2aAiySAea+U8bkh5dQF4lyQrumzJ5YTFvFN3AKsEiam/fudiY9tIS6cJTjC5swe+IwCpspvqlAARZJY2+s3cHEBxdTF47Ss20T5kwspl2z/KDHkjgFWCRN/fO9HUx4YBG14Sg92jZhzqRi2jVXfFOJAiySht58fyfj4/E9rk0BcyYW017xTTkJC7CZzTCzMjNbdcCxAWY238yWmdliMxuaqPOLZKr5pTsZP3MRNaEo3VoX8MikYjq0UHxTUSJXwDOBkQcduwP4qbsPAG6Jfywi9WRB6U6uvX8R1aHI/vh2bNE46LHkMBIWYHefB+w6+DDQPP5+C2Bzos4vkmkWrdvFtTMXxa/f25g5k4rp1FLxTWXJvhrajcALZnYXsfifdrgvNLNJwCSAbt26JWU4kYZqyYe7uGbGQqrqInRu2Zg5E4vprPimvGT/Eu5rwE3u3hW4CZh+uC9096nuXuTuRYWFhUkbUKShWbp+N+NmLKIyHt9HJhXTtbVewaIhSHaAxwFPxN//K6Bfwokcg7fW7+bq6QupqA3TqUU+cyYqvg1JsgO8GTgj/v6ZwNokn18kbSzfsGd/fDs0z2fOpGK6tVF8G5KE7QGb2RxgBNDWzDYCtwITgd+ZWQ5QQ3yPV0Q+nZUby7ly+gL21YZp37wRj0wq5rg2TYIeSz6lhAXY3Ucf5lODE3VOkUywalM5Y++bz76aMO2aNeKRSZ+he1vFtyHSM+FEGpBYfBewtyZMYbNGzJlUTA/Ft8FSgEUaiNWbY/Etrw7Rtmkj5kws5vjCpkGPJcdAARZpAN7evPeA+OYxZ+IwTmin+DZ0CrBIiivZupex981nT1WINk3ymD2xmF7tmwU9ltQDBVgkhb2zdR9jpy1gd1WI1vH49lZ804YCLJKi3t22jzHT5rOzso5WBbnMnjiMEzsovulEARZJQWsPiu+s64rp06H5J/9FaVAUYJEU815ZBaOnLWBHRR0tC3J5+LphnNxJ8U1Hyb4amogcwtySMqbMK6V0RwW7KusIRZwWjXN5eMIw+nZqEfR4kiAKsEjA5paUccvTq3F3dlbUEY46ZnDTWb3o11nxTWfaghAJ2JR5pYCzpbyGcNTJMujUIp8X3t4W9GiSYFoBiwTsgx0V7IivfLMMerRtQuPcbDburgp6NEkwrYBFArRhVxW7KkMfiW9BXk78ZYV0acl0pwCLBGTDriqumDqfukgUAzq2yKdxbjZVdWFCEWfy8J5BjygJpgCLBGDj7lh8N+2ppkleNj/4Uh+6tW5CeXWIds3yuW1UX0b0aRf0mJJg2gMWSbJNe6r3x7cgL5uZ44cypHtrJg4/PujRJMm0AhZJos17qrli6pts3B2L7/3XDGFI99ZBjyUBUYBFkmRLeWzlu2FXNY1zs5lxzRCG9WwT9FgSIAVYJAm2ltcweup81u+qIj83i+nXFFGs+GY8BVgkwbbtrWH0tPms21lFo5wsZowbwmnHtw16LEkBCrBIApXtja18P9hRSaOcLKaPG8JpJyi+EqMAiyRI2b7Yyrd0RyV5OVlMu7qIz/ZSfOXfFGCRBNi+r5Yx0xbw/vZ/x3d478Kgx5IUowCL1LMdFbWMmTaf98oqyMvOYspVgzlD8ZVDUIBF6tHOilrGTlvA2gPi+/kT9Yw2ObSEBdjMZphZmZmtOuj4N83sHTNbbWZ3JOr8Ism2q7KOsfct4J1t+8jNNu69chCf19OJ5WMkcgU8Exh54AEz+zxwAXCqu/cF7krg+UWSZnc8viVbY/H909jBnHVS+6DHkhSXsAC7+zxg10GHvwbc7u618a8pS9T5RZJlT1Usvmu27CUny7hnzCDOOVnxlU+W7D3g3sDnzGyBmb1mZkOSfH6RevWv+L59QHy/2LdD0GNJA5Hsq6HlAK2AYmAI8KiZ9XR3P/gLzWwSMAmgW7duSR1S5EiUV4W4avpCVm/eS3aW8fvRAxnZT/GVI5fsFfBG4AmPWQhEgUM+Mt3dp7p7kbsXFRbqITySWsqrQ1w1YwErN5WTnWX87ooBfOmUjkGPJQ1MsgP8N+BMADPrDeQBO5I8g8gx2VsT4uoZC1mxsZwsg99ePoDzT+0U9FjSACVsC8LM5gAjgLZmthG4FZgBzIg/NK0OGHeo7QeRVLWvJsTV0xeyfMOe/fEd1V/xlaOTsAC7++jDfOrKRJ1TJJH21YQYN2Mhy+Lx/c1lA7hgQOegx5IGTM+EEzkCFbVhrrl/EUvX78EM7rq0PxcOVHzl2CjAIp+gsjbMtfcvZMmHuzGDOy/pz0WDugQ9lqQBBVjkY8Tiu4hF62Lx/dXFp3LJYMVX6ocCLHIYVXVhxs9cxMJ1sSd03n7RKVxW1DXgqSSdKMAih1BdF2HCzMUs+CAW319edAqXD9ETgqR+KcAiB6muizDhgUW8WboTgJ9d2I/RQxVfqX8KsMgBakIRJj20mH++H4vv/1zYjyuLjwt4KklXCrBIXE0owsQHF/P62tiTM2+7oC9XKb6SQAqwCLH4Tn5oyf743vrlk7n6M92DHUrSXrKvhiaSMuaWlDFlXinrd1VSWRthT3UIgB+ddxLXnt4j4OkkEyjAkpHmlpRxy9OrycmCvdVh9tWGAbhiSFeu+1zPgKeTTPGJWxBmdr2ZtUrGMCLJMmVeKTlZsL2ibn982zTJ48OdVQFPJpnkSPaAOwCLzOxRMxtpZpbooUQSbf2uylh8a2Lx7dA8n44t8tm4WwGW5PnEALv7j4BewHTgGmCtmf3CzI5P8GwiCRGKRKmui+6Pb/vmjShs1ojqUIQurQoCnk4yyRE9CiJ+zd6t8T9hYi8r9JheVl4amlAkyg1z3mJXVR0ArQtyKWzaiKq6MKGIM3m49n8leT7xl3BmdgMwjtgrV9wHfNfdQ2aWBawF/juxI4rUj3Akyo2PLOO5VVsB+MrAzmwtr2Hj7iq6tCpg8vCejOjTLuApJZMcyaMg2gIXufuHBx5096iZnZ+YsUTqVzgS5Vt/WcazK7cAcOPZvbjx7N4BTyWZ7hMD7O63fMzn1tTvOCL1LxyJctOjy3l2RSy+N5x5guIrKUHPhJO0Fok63/nrcp5ZvhmA6z9/Ajedo/hKalCAJW1Fos5//XU5Ty2LxffrI47nO1/ojR5JKalCAZa0FIk63/3rcp58axMAk8/oyXe/eKLiKylFAZa0E40633t8BU/E4ztpeE9uHtlH8ZWUowBLWolGnZufWMFjSzYCcN1ne/D9cxVfSU0KsKSNaNT5wZMreXRxLL7jT+/BD887SfGVlKUAS1qIRp0f/m0VjyzaAMA1p3Xnx+crvpLaFGBp8NydHz+1ijkL1wMw7jPHceuXT1Z8JeUlLMBmNsPMysxs1SE+919m5mbWNlHnl8zg7tzy1GpmLYjF98ribvxkVF/FVxqERK6AZwIjDz5oZl2Bc4D1CTy3ZAB35ydPr+ah+bFnyY8d1o3bRvVTfKXBSFiA3X0esOsQn/otsQv4eKLOLenP3fnpM2/zwJux+I4e2pX/uaAfWVmKrzQcSd0DNrNRwCZ3X57M80p6cXd+9uwaZv5zHQCXF3Xl5xeeovhKg5O014QzswLgh8AXjvDrJwGTALp165bAyaQhcXd+8fc1TH/jAwAuHdyFX16k+ErDlMwV8PFAD2C5ma0DugBLzazDob7Y3ae6e5G7FxUWFiZxTElV7s7tz5Uw7fVYfC8e1IVfXXyq4isNVtJWwO6+Eth/tet4hIvcfUeyZpCGy92544V3mDKvFICLBnbmjksUX2nYEvkwtDnAm8CJZrbRzCYk6lyS3tydO194h3vnvg/AhQM6ceel/clWfKWBS9gK2N1Hf8Lnuyfq3JI+3J1fv/guf4rHd1T/Ttyl+Eqa0DPhJKX99uW13PPqewCcf2pHfnNZf3KydbeV9KB7sqSsu19+l9+/shaA807pyN2XD1B8Ja3o3iwp6fevrOXul2PxPbdfB+6+QvGV9KN7tKScP776Hr956V0ARvbtwO9HDyRX8ZU0pHu1pJQ/vvoed77wDgBfOLk9fxij+Er60j1bUsafX3t/f3zPObk994wZpPhKWtO9W1LC1Hnvc/tzJQCcfVI7/jhmEHk5untKetM9XAJ33+ul/OLvsfh+/sRC/jhW8ZXMoHu5BGrGGx/ws2fXADDixELuvXIwjXKyA55KJDmSdi0IkX+ZW1LGlHmlrNmylz3VIQCG9y7kz1cOJj9X8ZXMoQBLUs0tKeOWp1dTVRfeH9/8nCyuHNpN8ZWMoy0ISaop80qpqguzo6IOgKaNcujYMp/74xdXF8kkWgFLUq3Zupc9VbGVb5NG2RzXugAz2Li7KuDJRJJPK2BJmjkL1/87vnnZdG/dhKwsozoUoUurgoCnE0k+BViS4tFFG/j+EysBaJSTRbvmjTCDqrowoYgzeXjPgCcUST4FWBLu0cUb+N4TKwAY2r01v7t8AB2aN6a8OkS7ZvncNqovI/q0+4RbEUk/2gOWhHpsyUa+9/gK3KHouFbMuHYITRvlMPKUjkGPJhI4rYAlYZ5YupHvPrYcdxh8XCtmjh9K00b6N1/kXxRgSYi/vbWJ7/w1Ft+B3VoyM77yFZF/U4Cl3j21bBPffnQZ7jCga0seGD+UZvm5QY8lknIUYKlXzyzfzE1/WUbUoX/Xljw4YSjNFV+RQ1KApd48u2ILN8bje2qXFjw4XvEV+TgKsNSL51Zu4YZH3iISdfp1bs5D44fRorHiK/JxFGA5Zs+v2sI358Ti27dTcx6eMIwWBYqvyCdRgOWYvLB6K9fPfotw1DmpYyy+LQvygh5LpEFQgOWovfT2Nq6fvZRw1OnToRmzrhtGqyaKr8iRSliAzWyGmZWZ2aoDjt1pZiVmtsLMnjSzlok6vyTWK2u28fVZSwhFYvGdPbGY1oqvyKeSyBXwTGDkQcdeAvq5+6nAu8D3E3h+SZBXS8r42sNLCUWc3u2bMuu6YYqvyFFIWIDdfR6w66BjL7p7OP7hfKBLos4viTH3nTImP7SEukiUXu2aMntiMW2aNgp6LJEGKcg94PHAc4f7pJlNMrPFZrZ4+/btSRxLDue1d7czKR7fE+Lxbav4ihy1QAJsZj8EwsCsw32Nu0919yJ3LyosLEzecHJIr6/dzqQHF1MXjtKzsAmzrxtGYTPFV+RYJP3qKGY2DjgfOMvdPdnnl0/v/97bwXUPLKY2HKVn2yY8MrGYds3zgx5LpMFLaoDNbCTwPeAMd9eLgDUA/3xvBxMeWERtOEr3NgXMVnxF6k0iH4Y2B3gTONHMNprZBOAeoBnwkpktM7M/J+r8cuzefH8n4x9YRE0oynFtCpgzqZgOLRRfkfqSsBWwu48+xOHpiTqf1K/5pTsZPzMW326tC5gzsZiOLRoHPZZIWtEz4eQ/LCjdybX3L6I6FKFr68bMmVRMp5aKr0h9U4DlIxat28W1MxfFXyq+MXMmFtNZ8RVJCAVY9lvy4S6umbGQqroInVvG4tulVUHQY4mkLQVYAFi6fjfjZiyiMh7fRyYV07W14iuSSAqw8Nb63YybvpCK2jAdW+QzZ6LiK5IMCnCGW7ZhD1dPX8i+2jAdmufzyKRiurVRfEWSQQHOYCs27uGq6QvYVxumffNGzJlUzHFtmgQ9lkjGUIAz1KpN5Vx53wL21YRp16wRcyYW06Ot4iuSTApwBlq1qZyx9y1gb02YwmaxlW/PwqZBjyWScZJ+MR4JxtySMqbMK+X97RXsqqwjHHXaNo2tfI9XfEUCoQBngLklZdzy9Gqi7uysrCMSdbIMvn12L05op/iKBEVbEBlgyrxSou5sKa8hEnWys4zOLRvzzIotQY8mktG0As4ApTsq2FFRtz++Pds2oVFOFht364qgIkHSCjjNrd22j12V/45vj7ZNyM/Njl/rQY/3FQmSApzG3ivbx+hpCwhFYnu+HVs0Ij8ni6q6MKGIM3l4z6BHFMloCnCaeq+sgiumLmBHRS0tGudy6/l96dqqCeXVIdo1y+e2UX0Z0add0GOKZDTtAaeh97dXMGbafHZU1NI8P4dZ1w2jX+cWjDu9e9CjicgBtAJOMx/sqGT01PmU7aulWX4Os64rpl/nFkGPJSKHoACnkXUHxffhCcM4pYviK5KqFOA08eHOSkZPm8/WvTU0a5TDQxOG0b9ry6DHEpGPoQCngfU7qxg9dT5bymto2iiHByYMZYDiK5LyFOAGbsOuKkZPm8/m8hqa5GXzwPihDOrWKuixROQIKMAN2MbdVVwxdT6b9lTvj+/g4xRfkYZCAW6gNu2p3h/fgrxsZo4fSlH31kGPJSKfggLcAG3eU80VU99k4+5qGudmc/81Qxii+Io0OApwA7OlvJrR0+azYVc8vtcOYVjPNkGPJSJHIWEBNrMZZlZmZqsOONbazF4ys7Xxt9qw/BS2ltcweup8PtxZRX5uFtOvKaJY8RVpsBK5Ap4JjDzo2M3AK+7eC3gl/rEcgW17axgzbT7rdlbRKCeL6eOGcNrxbYMeS0SOQcIC7O7zgF0HHb4AeCD+/gPAhYk6fzop21vD6GnzKd1RSV5OFveNK+L0ExRfkYYu2XvA7d19C0D87WEvx2Vmk8xssZkt3r59e9IGTDVl++Lx3R6L77Sri/hcr8KgxxKRepCyv4Rz96nuXuTuRYWFmRmc7ftqGTttAe9vryQvO4upVw3mjN6Z+b0QSUfJDvA2M+sIEH9bluTzNxg7KmoZe9981pZVkJedxZSrBjPiRF2/VySdJDvATwPj4u+PA55K8vkbhJ0VsZXvu9sqyM02/nzVID6vi6eLpJ1EPgxtDvAmcKKZbTSzCcDtwDlmthY4J/6xHGBXZR1j71vAO9v2kZtt3Dt2MGf2aR/0WCKSAAl7RQx3H32YT52VqHM2dLsr6xgzbT4lW/eRk2XcM2YQZ5+s+Iqkq5T9JVym2VMVW/keGN8v9u0Q9FgikkAKcAr4V3zf3rKX7CzjnjEDGdlP8RVJdwpwwMqrQlw1fSGrN8fi+4fRAxnZr2PQY4lIEijAASqvDnH1jAWs3FROdpbx+ysG8qVTFF+RTKEAB2RvTYirZyxk+cZysgzuvnwA552q+IpkEgU4APtqQlw9fSHLN+why+C3lw/gy/07BT2WiCSZApxkFbVhxs1YyLINezCDX1/WnwsGdA56LBEJgAKcRBW1Ya6ZsZCl62PxveuS/nxlYJegxxKRgCjASVJZG+ba+xey+MPdmMEdF5/KxYMVX5FMlrBnwgnMLSljyrxSPtxVyb6aMPtqwgD86qJTubSoa8DTiUjQFOAEmVtSxi1PryY7K/ZY38q6CADXntady4YoviKiLYiEmTKvlOwsKNtbuz++hU3zKNm6L+DJRCRVaAWcIB/uqvzIyrdTy3xaF+SxcXdVwJOJSKrQCjgBakIRKmsj/45vi3zaNGlEdShCl1YFAU8nIqlCAa5nNaEIEx9cTHl1CIC2TfNo3SSPqrowoYgzeXjPgCcUkVShLYh6VBOKMPmhJby+dgcAY4Z25YMdVWzcXUWXVgVMHt6TEXplCxGJU4DrSW04wlcfXsJr78ZewflH553EdZ/TaldEDk9bEPWgNhzhaw8vZe47iq+IHDkF+BjVhaN8Y9ZS/lESe4HnH3ypj+IrIkdEAT4GdeEo35i9lJfXxOJ787l9mDT8+ICnEpGGQgE+SqFIlG/OWcpLb28D4L9HnshXz1B8ReTIKcBHIRSJ8s3Zb/HC6lh8/+sLvfn6iBMCnkpEGhoF+FMKRaJ865G3eH71VgC+fU5vrj+zV8BTiUhDpAB/CuFIlJv+soy/r4zF98aze3HDWYqviBwdBfgIhSNRbnp0Of+7YgsAN5zVixvP7h3wVCLSkCnARyASdb7z1+U8s3wzANd//gRuOlsrXxE5NoEE2MxuMrPVZrbKzOaYWX4QcxyJSNT57l+X89SyWHy/PuJ4vvOF3phZwJOJSEOX9ACbWWfgBqDI3fsB2cAVyZ7jSESizncfW84Tb20CYPIZPfnuF09UfEWkXgS1BZEDNDazHKAA2BzQHIcVjTrfe3wFTyyNxXfS8J7cPLKP4isi9SbpAXb3TcBdwHpgC1Du7i8e/HVmNsnMFpvZ4u3btyd1xmjUufmJFTy2ZCMAEz7bg++fq/iKSP0KYguiFXAB0APoBDQxsysP/jp3n+ruRe5eVFhYmLT5olHnB0+u5NHFsfhee3p3fnTeSYqviNS7ILYgzgY+cPft7h4CngBOC2CO/xCNOj/82yoeWbQBgGtO684t55+s+IpIQgQR4PVAsZkVWKxsZwFrApjjI9ydHz+1ijkL1wNw9WeO49YvK74ikjhB7AEvAB4DlgIr4zNMTfYcB83ELU+tZtaCWHyvLO7GT0f1VXxFJKECeUUMd78VuDWIcx/M3fnpM2/z0PwPARgzrBu3jeqn+IpIwmX0M+Hcndv+921m/nMdAKOHduVnF/QjK0vxFZHEy9gAuzs/e3YN9//fOgAuL+rKzy88RfEVkaTJyAC7O7/4+xqmv/EBAJcO7sIvL1J8RSS5Mi7A7s7tz5cw7fVYfC8e1IVfXXyq4isiSZdRAXZ37njhHaa8VgrARQM7c8cliq+IBCNjAuzu/PrFd7l37vsAXDigE3de2p9sxVdEApIRAXZ3fvPSu9zz6nsAjOrfiV9fNkDxFZFAZUSA7355LX/4Ryy+55/akd9cppWviAQv7QP8u5fX8rtX1gJw3ikdufvyAeRkp/1/tog0AIE8Ey7R5paUMWVeKas3l7O3JgzAuf06cPcViq+IpI60C/DckjJueXo1FTWh/fFtnJvNxYM6k6v4ikgKSbsiTZlXSmVtmF1VIQCa5+fQsUUjpr+xLtjBREQOknYB3rC7ipaNc8k2o1l+Dl1bF1CQl8PG3VVBjyYi8hFptwXRtVUBZftqOL6wCbk5WWSZUVUXpkurgqBHExH5iLRbAU8e3pNQxIm4Y0BVXZhQxJk8vGfQo4mIfETaBXhEn3bcNqov7ZrlU14dol2zfG4b1ZcRfdoFPZqIyEek3RYExCKs4IpIqku7FbCISEOhAIuIBEQBFhEJiAIsIhIQBVhEJCAKsIhIQBRgEZGAKMAiIgFRgEVEAmLuHvQMn8jMtgMfHsVfbQvsqOdxjkaqzAGa5VBSZQ7QLIeSKnPA0c+yw91HHnywQQT4aJnZYncv0hz/pllSdw7QLKk8B9T/LNqCEBEJiAIsIhKQdA/w1KAHiEuVOUCzHEqqzAGa5VBSZQ6o51nSeg9YRCSVpfsKWEQkZSnAIiIBScsAm9kMMyszs1UBz9HVzF41szVmttrMvhXgLPlmttDMlsdn+WlQs8TnyTazt8zsfwOeY52ZrTSzZWa2OMA5WprZY2ZWEr+/fCagOU6Mfy/+9Wevmd0YxCzxeW6K319XmdkcM8sPaI5vxWdYXZ/fj7TcAzaz4UAF8KC79wtwjo5AR3dfambNgCXAhe7+dgCzGNDE3SvMLBd4A/iWu89P9izxeb4NFAHN3f38IGaIz7EOKHL3QB/ob2YPAK+7+31mlgcUuPuegGfKBjYBw9z9aJ4Idazn70zsfnqyu1eb2aPA3919ZpLn6Ac8AgwF6oDnga+5+9pjve20XAG7+zxgVwrMscXdl8bf3wesAToHNIu7e0X8w9z4n0D+9TWzLsB5wH1BnD/VmFlzYDgwHcDd64KOb9xZwPtBxPcAOUBjM8sBCoDNAcxwEjDf3avcPQy8BnylPm44LQOcisysOzAQWBDgDNlmtgwoA15y96BmuRv4byAa0PkP5MCLZrbEzCYFNENPYDtwf3xb5j4zaxLQLAe6ApgT1MndfRNwF7Ae2AKUu/uLAYyyChhuZm3MrAD4EtC1Pm5YAU4CM2sKPA7c6O57g5rD3SPuPgDoAgyN/2iVVGZ2PlDm7kuSfe7DON3dBwHnAt+Ib18lWw4wCLjX3QcClcDNAcyxX3wbZBTw1wBnaAVcAPQAOgFNzOzKZM/h7muAXwEvEdt+WA6E6+O2FeAEi++3Pg7Mcvcngp4HIP7j7VzgPy4OkgSnA6Pie6+PAGea2cMBzAGAu2+Ovy0DniS2z5dsG4GNB/xE8hixIAfpXGCpu28LcIazgQ/cfbu7h4AngNOCGMTdp7v7IHcfTmx785j3f0EBTqj4L76mA2vc/TcBz1JoZi3j7zcmducuSfYc7v59d+/i7t2J/Yj7D3dP+qoGwMyaxH85SvxH/i8Q+3Ezqdx9K7DBzE6MHzoLSPovag8ymgC3H+LWA8VmVhD/f+ksYr9HSTozaxd/2w24iHr63uTUx42kGjObA4wA2prZRuBWd58ewCinA1cBK+N7rwA/cPe/BzBLR+CB+G+2s4BH3T3Qh4ClgPbAk7H/t8kBZrv78wHN8k1gVvxH/1Lg2oDmIL7PeQ4wOagZANx9gZk9Biwl9iP/WwT3tOTHzawNEAK+4e676+NG0/JhaCIiDYG2IEREAqIAi4gERAEWEQmIAiwiEhAFWEQkIAqwiEhAFGARkYAowJKxzGyIma2IXyu5Sfxar4FdvlQyj56IIRnNzH4G5AONiV2P4ZcBjyQZRAGWjBZ/6u8ioAY4zd0jAY8kGURbEJLpWgNNgWbEVsIiSaMVsGQ0M3ua2GUxexB7+ajrAx5JMkhaXg1N5EiY2dVA2N1nx68S908zO9Pd/xH0bJIZtAIWEQmI9oBFRAKiAIuIBEQBFhEJiAIsIhIQBVhEJCAKsIhIQBRgEZGA/D+P7YmepNUodgAAAABJRU5ErkJggg==","text/plain":["<Figure size 360x360 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["x = np.arange(1, 10)\n","y = 2 * x + 5\n","\n","data = pd.DataFrame({'x': x, 'y': y})\n","\n","sns.lmplot(x='x', y='y', data=data)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Object `sns.implot` not found.\n"]}],"source":[]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1;31mSignature:\u001b[0m\n","\u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlmplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mhue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mcol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mrow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mpalette\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mcol_wrap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0maspect\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mmarkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'o'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0msharex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0msharey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mhue_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mcol_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mrow_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mlegend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mlegend_out\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mx_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mx_bins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mx_ci\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ci'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mscatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mfit_reg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mci\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m95\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mn_boot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mlogistic\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mlowess\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mrobust\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mlogx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mx_partial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0my_partial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mtruncate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mx_jitter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0my_jitter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mscatter_kws\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mline_kws\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mfacet_kws\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mDocstring:\u001b[0m\n","Plot data and regression model fits across a FacetGrid.\n","\n","This function combines :func:`regplot` and :class:`FacetGrid`. It is\n","intended as a convenient interface to fit regression models across\n","conditional subsets of a dataset.\n","\n","When thinking about how to assign variables to different facets, a general\n","rule is that it makes sense to use ``hue`` for the most important\n","comparison, followed by ``col`` and ``row``. However, always think about\n","your particular dataset and the goals of the visualization you are\n","creating.\n","\n","There are a number of mutually exclusive options for estimating the\n","regression model. See the :ref:`tutorial <regression_tutorial>` for more\n","information.    \n","\n","The parameters to this function span most of the options in\n",":class:`FacetGrid`, although there may be occasional cases where you will\n","want to use that class and :func:`regplot` directly.\n","\n","Parameters\n","----------\n","x, y : strings, optional\n","    Input variables; these should be column names in ``data``.\n","data : DataFrame\n","    Tidy (\"long-form\") dataframe where each column is a variable and each\n","    row is an observation.    \n","hue, col, row : strings\n","    Variables that define subsets of the data, which will be drawn on\n","    separate facets in the grid. See the ``*_order`` parameters to control\n","    the order of levels of this variable.\n","palette : palette name, list, or dict\n","    Colors to use for the different levels of the ``hue`` variable. Should\n","    be something that can be interpreted by :func:`color_palette`, or a\n","    dictionary mapping hue levels to matplotlib colors.    \n","col_wrap : int\n","    \"Wrap\" the column variable at this width, so that the column facets\n","    span multiple rows. Incompatible with a ``row`` facet.    \n","height : scalar\n","    Height (in inches) of each facet. See also: ``aspect``.    \n","aspect : scalar\n","    Aspect ratio of each facet, so that ``aspect * height`` gives the width\n","    of each facet in inches.    \n","markers : matplotlib marker code or list of marker codes, optional\n","    Markers for the scatterplot. If a list, each marker in the list will be\n","    used for each level of the ``hue`` variable.\n","share{x,y} : bool, 'col', or 'row' optional\n","    If true, the facets will share y axes across columns and/or x axes\n","    across rows.    \n","\n","    .. deprecated:: 0.12.0\n","        Pass using the `facet_kws` dictionary.\n","\n","{hue,col,row}_order : lists, optional\n","    Order for the levels of the faceting variables. By default, this will\n","    be the order that the levels appear in ``data`` or, if the variables\n","    are pandas categoricals, the category order.\n","legend : bool, optional\n","    If ``True`` and there is a ``hue`` variable, add a legend.\n","legend_out : bool\n","    If ``True``, the figure size will be extended, and the legend will be\n","    drawn outside the plot on the center right.    \n","\n","    .. deprecated:: 0.12.0\n","        Pass using the `facet_kws` dictionary.\n","\n","x_estimator : callable that maps vector -> scalar, optional\n","    Apply this function to each unique value of ``x`` and plot the\n","    resulting estimate. This is useful when ``x`` is a discrete variable.\n","    If ``x_ci`` is given, this estimate will be bootstrapped and a\n","    confidence interval will be drawn.    \n","x_bins : int or vector, optional\n","    Bin the ``x`` variable into discrete bins and then estimate the central\n","    tendency and a confidence interval. This binning only influences how\n","    the scatterplot is drawn; the regression is still fit to the original\n","    data.  This parameter is interpreted either as the number of\n","    evenly-sized (not necessary spaced) bins or the positions of the bin\n","    centers. When this parameter is used, it implies that the default of\n","    ``x_estimator`` is ``numpy.mean``.    \n","x_ci : \"ci\", \"sd\", int in [0, 100] or None, optional\n","    Size of the confidence interval used when plotting a central tendency\n","    for discrete values of ``x``. If ``\"ci\"``, defer to the value of the\n","    ``ci`` parameter. If ``\"sd\"``, skip bootstrapping and show the\n","    standard deviation of the observations in each bin.    \n","scatter : bool, optional\n","    If ``True``, draw a scatterplot with the underlying observations (or\n","    the ``x_estimator`` values).    \n","fit_reg : bool, optional\n","    If ``True``, estimate and plot a regression model relating the ``x``\n","    and ``y`` variables.    \n","ci : int in [0, 100] or None, optional\n","    Size of the confidence interval for the regression estimate. This will\n","    be drawn using translucent bands around the regression line. The\n","    confidence interval is estimated using a bootstrap; for large\n","    datasets, it may be advisable to avoid that computation by setting\n","    this parameter to None.    \n","n_boot : int, optional\n","    Number of bootstrap resamples used to estimate the ``ci``. The default\n","    value attempts to balance time and stability; you may want to increase\n","    this value for \"final\" versions of plots.    \n","units : variable name in ``data``, optional\n","    If the ``x`` and ``y`` observations are nested within sampling units,\n","    those can be specified here. This will be taken into account when\n","    computing the confidence intervals by performing a multilevel bootstrap\n","    that resamples both units and observations (within unit). This does not\n","    otherwise influence how the regression is estimated or drawn.    \n","seed : int, numpy.random.Generator, or numpy.random.RandomState, optional\n","    Seed or random number generator for reproducible bootstrapping.    \n","order : int, optional\n","    If ``order`` is greater than 1, use ``numpy.polyfit`` to estimate a\n","    polynomial regression.    \n","logistic : bool, optional\n","    If ``True``, assume that ``y`` is a binary variable and use\n","    ``statsmodels`` to estimate a logistic regression model. Note that this\n","    is substantially more computationally intensive than linear regression,\n","    so you may wish to decrease the number of bootstrap resamples\n","    (``n_boot``) or set ``ci`` to None.    \n","lowess : bool, optional\n","    If ``True``, use ``statsmodels`` to estimate a nonparametric lowess\n","    model (locally weighted linear regression). Note that confidence\n","    intervals cannot currently be drawn for this kind of model.    \n","robust : bool, optional\n","    If ``True``, use ``statsmodels`` to estimate a robust regression. This\n","    will de-weight outliers. Note that this is substantially more\n","    computationally intensive than standard linear regression, so you may\n","    wish to decrease the number of bootstrap resamples (``n_boot``) or set\n","    ``ci`` to None.    \n","logx : bool, optional\n","    If ``True``, estimate a linear regression of the form y ~ log(x), but\n","    plot the scatterplot and regression model in the input space. Note that\n","    ``x`` must be positive for this to work.    \n","{x,y}_partial : strings in ``data`` or matrices\n","    Confounding variables to regress out of the ``x`` or ``y`` variables\n","    before plotting.    \n","truncate : bool, optional\n","    If ``True``, the regression line is bounded by the data limits. If\n","    ``False``, it extends to the ``x`` axis limits.\n","\n","{x,y}_jitter : floats, optional\n","    Add uniform random noise of this size to either the ``x`` or ``y``\n","    variables. The noise is added to a copy of the data after fitting the\n","    regression, and only influences the look of the scatterplot. This can\n","    be helpful when plotting variables that take discrete values.    \n","{scatter,line}_kws : dictionaries\n","    Additional keyword arguments to pass to ``plt.scatter`` and\n","    ``plt.plot``.    \n","facet_kws : dict\n","    Dictionary of keyword arguments for :class:`FacetGrid`.\n","\n","See Also\n","--------\n","regplot : Plot data and a conditional model fit.\n","FacetGrid : Subplot grid for plotting conditional relationships.\n","pairplot : Combine :func:`regplot` and :class:`PairGrid` (when used with\n","           ``kind=\"reg\"``).\n","\n","Notes\n","-----\n","\n","The :func:`regplot` and :func:`lmplot` functions are closely related, but\n","the former is an axes-level function while the latter is a figure-level\n","function that combines :func:`regplot` and :class:`FacetGrid`.    \n","\n","Examples\n","--------\n","\n","These examples focus on basic regression model plots to exhibit the\n","various faceting options; see the :func:`regplot` docs for demonstrations\n","of the other options for plotting the data and models. There are also\n","other examples for how to manipulate plot using the returned object on\n","the :class:`FacetGrid` docs.\n","\n","Plot a simple linear relationship between two variables:\n","\n",".. plot::\n","    :context: close-figs\n","\n","    >>> import seaborn as sns; sns.set_theme(color_codes=True)\n","    >>> tips = sns.load_dataset(\"tips\")\n","    >>> g = sns.lmplot(x=\"total_bill\", y=\"tip\", data=tips)\n","\n","Condition on a third variable and plot the levels in different colors:\n","\n",".. plot::\n","    :context: close-figs\n","\n","    >>> g = sns.lmplot(x=\"total_bill\", y=\"tip\", hue=\"smoker\", data=tips)\n","\n","Use different markers as well as colors so the plot will reproduce to\n","black-and-white more easily:\n","\n",".. plot::\n","    :context: close-figs\n","\n","    >>> g = sns.lmplot(x=\"total_bill\", y=\"tip\", hue=\"smoker\", data=tips,\n","    ...                markers=[\"o\", \"x\"])\n","\n","Use a different color palette:\n","\n",".. plot::\n","    :context: close-figs\n","\n","    >>> g = sns.lmplot(x=\"total_bill\", y=\"tip\", hue=\"smoker\", data=tips,\n","    ...                palette=\"Set1\")\n","\n","Map ``hue`` levels to colors with a dictionary:\n","\n",".. plot::\n","    :context: close-figs\n","\n","    >>> g = sns.lmplot(x=\"total_bill\", y=\"tip\", hue=\"smoker\", data=tips,\n","    ...                palette=dict(Yes=\"g\", No=\"m\"))\n","\n","Plot the levels of the third variable across different columns:\n","\n",".. plot::\n","    :context: close-figs\n","\n","    >>> g = sns.lmplot(x=\"total_bill\", y=\"tip\", col=\"smoker\", data=tips)\n","\n","Change the height and aspect ratio of the facets:\n","\n",".. plot::\n","    :context: close-figs\n","\n","    >>> g = sns.lmplot(x=\"size\", y=\"total_bill\", hue=\"day\", col=\"day\",\n","    ...                data=tips, height=6, aspect=.4, x_jitter=.1)\n","\n","Wrap the levels of the column variable into multiple rows:\n","\n",".. plot::\n","    :context: close-figs\n","\n","    >>> g = sns.lmplot(x=\"total_bill\", y=\"tip\", col=\"day\", hue=\"day\",\n","    ...                data=tips, col_wrap=2, height=3)\n","\n","Condition on two variables to make a full grid:\n","\n",".. plot::\n","    :context: close-figs\n","\n","    >>> g = sns.lmplot(x=\"total_bill\", y=\"tip\", row=\"sex\", col=\"time\",\n","    ...                data=tips, height=3)\n","\n","Use methods on the returned :class:`FacetGrid` instance to further tweak\n","the plot:\n","\n",".. plot::\n","    :context: close-figs\n","\n","    >>> g = sns.lmplot(x=\"total_bill\", y=\"tip\", row=\"sex\", col=\"time\",\n","    ...                data=tips, height=3)\n","    >>> g = (g.set_axis_labels(\"Total bill (US Dollars)\", \"Tip\")\n","    ...       .set(xlim=(0, 60), ylim=(0, 12),\n","    ...            xticks=[10, 30, 50], yticks=[2, 6, 10])\n","    ...       .fig.subplots_adjust(wspace=.02))\n","\u001b[1;31mSource:\u001b[0m   \n","\u001b[1;33m@\u001b[0m\u001b[0m_deprecate_positional_args\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;32mdef\u001b[0m \u001b[0mlmplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mhue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# TODO move before data once * is enforced\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mpalette\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_wrap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"o\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0msharex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msharey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhue_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mlegend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlegend_out\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_bins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mx_ci\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ci\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_reg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mci\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m95\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_boot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogistic\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlowess\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mrobust\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_partial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_partial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mtruncate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_jitter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_jitter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscatter_kws\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mline_kws\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfacet_kws\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;31m# Handle deprecations\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mheight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"The `size` parameter has been renamed to `height`; \"\u001b[0m\u001b[1;33m\n","\u001b[0m               \u001b[1;34m\"please update your code.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUserWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mfacet_kws\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mfacet_kws\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mfacet_kw_deprecation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[1;34mf\"{key} is deprecated from the `lmplot` function signature. \"\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[1;34m\"Please update your code to pass it using `facet_kws`.\"\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUserWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mfacet_kws\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mfacet_kw_deprecation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sharex\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msharex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mfacet_kw_deprecation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sharey\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msharey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mfacet_kw_deprecation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"legend_out\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlegend_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Missing required keyword argument `data`.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;31m# Reduce the dataframe to only needed columns\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mneed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_partial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_partial\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mneed_cols\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;31m# Initialize the grid\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mfacets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFacetGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mpalette\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpalette\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mrow_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrow_order\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcol_order\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhue_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhue_order\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maspect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_wrap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcol_wrap\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;33m**\u001b[0m\u001b[0mfacet_kws\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;31m# Add the markers here as FacetGrid has figured out how many levels of the\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;31m# hue variable are needed and we don't want to duplicate that process\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mfacets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhue_names\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mn_markers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mn_markers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfacets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhue_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmarkers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mmarkers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmarkers\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_markers\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmarkers\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_markers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"markers must be a singeton or a list of markers \"\u001b[0m\u001b[1;33m\n","\u001b[0m                          \u001b[1;34m\"for each level of the hue variable\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mfacets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhue_kws\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"marker\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmarkers\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mupdate_datalim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mxys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_datalim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdatey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautoscale_view\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mfacets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mupdate_datalim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;31m# Draw the regression plot on each facet\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mregplot_kws\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mx_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_estimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_bins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_bins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_ci\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_ci\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mscatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_reg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mci\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mci\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_boot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_boot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogistic\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogistic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlowess\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlowess\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mrobust\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrobust\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_partial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_partial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_partial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_partial\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mtruncate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_jitter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_jitter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_jitter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_jitter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mscatter_kws\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscatter_kws\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline_kws\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mline_kws\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mfacets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregplot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mregplot_kws\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[0mfacets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_axis_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;31m# Add a legend\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mlegend\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhue\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhue\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mfacets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_legend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mfacets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mFile:\u001b[0m      c:\\users\\jason\\anaconda3\\lib\\site-packages\\seaborn\\regression.py\n","\u001b[1;31mType:\u001b[0m      function\n"]}],"source":["sns.lmplot??"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":4}
